{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNiMoNIieMcP"
      },
      "source": [
        "Packages required for GridWorld:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f15N7hM2dks4"
      },
      "source": [
        "import numpy as np\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNQ15tVLeSUt"
      },
      "source": [
        "Functions to show the map and policy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XFD_e0_eRoO"
      },
      "source": [
        "def printMap(world):\n",
        "  # Shows GridWorld map\n",
        "  m = \"[\"\n",
        "  for i in range(world.size[0]):\n",
        "    for j in range(world.size[1]):\n",
        "      if world.map[(i, j)] == 0: \n",
        "        m += \" O \"\n",
        "      elif world.map[(i, j)] == -1:\n",
        "        m += \" X \" \n",
        "      else:\n",
        "        m += \" F \"\n",
        "    if i == world.size[0] - 1:\n",
        "      m += \"]\\n\"\n",
        "    else:\n",
        "      m += \"\\n\"\n",
        "  print(m)\n",
        "\n",
        "def printPolicy(world, policy):\n",
        "  # Shows policy\n",
        "  p = \"[\"\n",
        "  for i in range(world.size[0]):\n",
        "    for j in range(world.size[1]):\n",
        "      if policy[i][j] == 0:\n",
        "        p += \" ^ \"\n",
        "      elif policy[i][j] == 1:\n",
        "        p += \" V \"\n",
        "      elif policy[i][j] == 2:\n",
        "        p += \" < \"\n",
        "      else:\n",
        "        p += \" > \"\n",
        "    if i == world.size[0] - 1:\n",
        "      p += \"]\\n\" \n",
        "    else:\n",
        "      p += \"\\n\"\n",
        "  print(p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-R2nTfKnebWA"
      },
      "source": [
        "# *World* Class: \n",
        "\n",
        "This class stores the information of the world:\n",
        "\n",
        "*   *Map*: Matrix that encodes the world with free cells (0), obstacles (-1) and terminal cells (1)\n",
        "*   *Size*: Vector with the size of the world encoding matrix (width, height)\n",
        "\n",
        "The following data is required to create a world:\n",
        "\n",
        "*   Map size (width, height)\n",
        "*   Terminal cell list\n",
        "*   Obstacle cell list\n",
        "\n",
        "For instance: \n",
        "\n",
        "w = World((10, 10), [(9, 9)], [(2, 4), (4, 2)])\n",
        "\n",
        "Creates a world with 10 rows and 10 columns with a terminal state (9, 9) and two obstacles in (2, 4) and (4, 2).\n",
        "\n",
        "![map1.PNG](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IhxtgsWeaeX"
      },
      "source": [
        "class World:\n",
        "\n",
        "  def __init__(self, size, terminal, obstacle):\n",
        "    # Creates a world\n",
        "    self.size = size\n",
        "    self.map = {}\n",
        "    for i in range(size[0]):\n",
        "      for j in range(size[1]):\n",
        "        # Free states\n",
        "        self.map[(i, j)] = 0\n",
        "        # Terminal states\n",
        "        for t in terminal:\n",
        "          if i==t[0] and j==t[1]:\n",
        "            self.map[(i, j)] = 1\n",
        "        # Obstacle states\n",
        "        for o in obstacle:\n",
        "          if i==o[0] and j==o[1]:\n",
        "            self.map[(i, j)] = -1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FI_a4644fkDp"
      },
      "source": [
        "Test for the *World* class:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoGTcjNwfiZ0",
        "outputId": "a2f2746d-0b0a-4d33-ee60-0b9e49d8841a"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "  w = World((10, 10), [(9, 9)], [(2, 4), (4, 2)])\n",
        "  printMap(w)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ O  O  O  O  O  O  O  O  O  O \n",
            " O  O  O  O  O  O  O  O  O  O \n",
            " O  O  O  O  X  O  O  O  O  O \n",
            " O  O  O  O  O  O  O  O  O  O \n",
            " O  O  X  O  O  O  O  O  O  O \n",
            " O  O  O  O  O  O  O  O  O  O \n",
            " O  O  O  O  O  O  O  O  O  O \n",
            " O  O  O  O  O  O  O  O  O  O \n",
            " O  O  O  O  O  O  O  O  O  O \n",
            " O  O  O  O  O  O  O  O  O  F ]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8oXNKPFfyIi"
      },
      "source": [
        "# *Agent* class:\n",
        "\n",
        "This class controls the agent that learns by Reinforce Learning in *GridWorld*. \n",
        "\n",
        "The following data is required to create an agent:\n",
        "\n",
        "*   *World*: World of the agent.\n",
        "*   *Initial State*: Initial state of the agent.\n",
        "\n",
        "The follosing methods are used to control the agent:\n",
        "\n",
        "*   *nextState = move(state, action)*: Moves the agent from *state* to *nextState* applying *action*.\n",
        "*   *reward = reward(nextState)*: Returns the *reward* received by the agent when going to *nextState*.\n",
        "*   *nextState, reward = checkAction(state, action)*: Checks the *nextState* and *reward* when the agent takes the *action* in the *state*. This method do not change the internal state of the agent, so it can be used to sweep the state space.\n",
        "*   *nextState, reward = executeAction(action)*: Executes the *action* in the current state and returns the *nextState* and *reward*. This method changes the internal state of the agent, so it should only be used when the agent travels along the world.\n",
        "\n",
        "**Exercise**:\n",
        "\n",
        "Try different rewards to see their influence on the behavior of the agent when executing the policy and value-based algorithms of this sheet."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkBeH-cwdjtn"
      },
      "source": [
        "# GridWorld:\n",
        "\n",
        "*GridWorld* is a world in the form of a board widely used as test environment in Reinforcement Learning. This board has several types of cells: initial, free, obstacles, terminal... The agents must go from the initial cell to the terminal one avoiding the obstacles and traveling the minimum distance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjYz4_W9ftaV"
      },
      "source": [
        "class Agent:\n",
        "\n",
        "  def __init__(self, world, initialState):\n",
        "    # Creates an agent\n",
        "    self.world = world\n",
        "    self.state = np.array(initialState)\n",
        "\n",
        "  def move(self, state, action):\n",
        "    # Manages state transitions\n",
        "    nextState = state + np.array(action)\n",
        "    if nextState[0] < 0:\n",
        "      nextState[0] = 0\n",
        "    elif nextState[0] >= self.world.size[0]:\n",
        "      nextState[0] = self.world.size[0] - 1\n",
        "    if nextState[1] < 0:\n",
        "      nextState[1] = 0\n",
        "    elif nextState[1] >= self.world.size[1]:\n",
        "      nextState[1] = self.world.size[1] - 1\n",
        "    return nextState\n",
        "\n",
        "  def reward(self, nextState):\n",
        "    # Manages rewards\n",
        "    if self.world.map[(nextState[0], nextState[1])] == 0:\n",
        "      # Reward when the agent moves to a free cell\n",
        "      reward = 0 # ** Try different values ** \n",
        "    elif self.world.map[(nextState[0], nextState[1])] == -1:\n",
        "      # Reward when the agent tries to move to an obstacle\n",
        "      reward = -1 # ** Try different values **\n",
        "    elif self.world.map[(nextState[0], nextState[1])] == 1:\n",
        "      # Reward when the agent moves to a terminal cell\n",
        "      reward = 1 # ** Try different values **\n",
        "    return reward\n",
        "\n",
        "  def checkAction(self, state, action):\n",
        "    # Planifica una acción\n",
        "    nextState = self.move(state, action)\n",
        "    if self.world.map[(state[0], state[1])] == -1: \n",
        "      nextState = state                            \n",
        "    reward = self.reward(nextState)\n",
        "    return nextState, reward\n",
        "\n",
        "  def executeAction(self, action):\n",
        "    # Planifica y ejecuta una acción\n",
        "    nextState = self.move(self.state, action)\n",
        "    if self.world.map[(self.state[0], self.state[1])] == -1: \n",
        "      nextState = self.state                                 \n",
        "    else:\n",
        "      self.state = nextState\n",
        "    reward = self.reward(nextState)\n",
        "    return self.state, reward  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoqakHx-h32J"
      },
      "source": [
        "Prueba de la clase *Agent*:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjkU9mjwhWif",
        "outputId": "538fbf24-25bc-4f80-87d1-5877784d082c"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "  # Create the world\n",
        "  w = World((10, 10), [(9, 9)], [(2, 4), (4, 2)])\n",
        "  # Create the agent\n",
        "  a = Agent(w, (0, 0))\n",
        "  # Move the agent through the main diagonal\n",
        "  \n",
        "  for i in range(1,10):\n",
        "    # Show every new state and its reward\n",
        "    print(a.executeAction((1, 1)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([1, 1]), 0)\n",
            "(array([2, 2]), 0)\n",
            "(array([3, 3]), 0)\n",
            "(array([4, 4]), 0)\n",
            "(array([5, 5]), 0)\n",
            "(array([6, 6]), 0)\n",
            "(array([7, 7]), 0)\n",
            "(array([8, 8]), 0)\n",
            "(array([9, 9]), 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y32CbC01iHBF"
      },
      "source": [
        "# Policy-based method:\n",
        "\n",
        "This is a policy-based algorithm that allows the agent to learn how to move through *GridWorld*.\n",
        "\n",
        "The agent must go from (0, 0) to (9, 9) avoiding obstacles in (4, 2) and (2, 4). The movements of the agent can be left (-1, 0), right (1, 0), up (0, -1), and down (0, 1).\n",
        "\n",
        "**Policy evaluation exercise**: \n",
        "\n",
        "Try the algorithm that evaluates the random policy with the previously described actions (left, right, up, and down)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eF6J_gbpiF-F",
        "outputId": "563d00cb-46ba-40f7-d47d-9ef621a8b272"
      },
      "source": [
        "# Policy evaluation\n",
        "if __name__== \"__main__\":\n",
        "  # Create the world\n",
        "  w = World((10, 10), [(9, 9)], [(4, 2), (2, 4)])\n",
        "  # Create the agent\n",
        "  agent = Agent(w, (0, 0))\n",
        "  # Create the policy\n",
        "  actions = [(-1, 0), (1, 0), (0, -1), (0, 1)] # ** Try other policies **\n",
        "  # Initialize the value matrix (all to zero)\n",
        "  v = []\n",
        "  v.append(np.zeros(w.size)) \n",
        "  # Loop 1: Repeat until the value diference is neglectable\n",
        "  theta = 0.01\n",
        "  for epoch in range(1,1000):\n",
        "    vp = np.zeros(w.size)\n",
        "    # Loop 2: Sweep the state space to update the values\n",
        "    for i in range(w.size[0]):\n",
        "      for j in range(w.size[1]):\n",
        "        state = (i, j)\n",
        "        # Loop 3: Sweep the possible actions\n",
        "        for k in range(len(actions)):\n",
        "          action = actions[k]\n",
        "          # Estimate the transitions and rewards\n",
        "          nextState, reward = agent.checkAction(state, action)\n",
        "          # Update the value\n",
        "          vp[i][j] += 1/len(actions) * (reward + v[epoch-1][nextState[0]][nextState[1]])\n",
        "    v.append(vp) # Save all the values to analyze them, but the algorithm only needs the two last values.\n",
        "    # Difference between the two last matrices\n",
        "    dif = np.abs(np.subtract(v[epoch-1], v[epoch-2]))\n",
        "    value = np.max(dif) / np.max(vp)\n",
        "    if value < theta: \n",
        "      print('Época: ' + str(epoch))\n",
        "      print('Matriz de valor: ' + str(vp))  \n",
        "      break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Época: 68\n",
            "Matriz de valor: [[-2.82407283e+01 -2.97052095e+01 -3.21319312e+01 -3.44849371e+01\n",
            "  -3.49108603e+01 -2.97415728e+01 -2.33181490e+01 -1.78879909e+01\n",
            "  -1.41802226e+01 -1.23315193e+01]\n",
            " [-2.97052095e+01 -3.17055516e+01 -3.52132639e+01 -3.94334637e+01\n",
            "  -4.34421526e+01 -3.36282672e+01 -2.45991792e+01 -1.81265270e+01\n",
            "  -1.40583625e+01 -1.21048860e+01]\n",
            " [-3.21319312e+01 -3.52132639e+01 -4.06787257e+01 -4.77658704e+01\n",
            "  -6.80000000e+01 -3.94738345e+01 -2.56200158e+01 -1.79070833e+01\n",
            "  -1.35326282e+01 -1.15169307e+01]\n",
            " [-3.44849371e+01 -3.94334637e+01 -4.77658704e+01 -4.53625114e+01\n",
            "  -4.45884177e+01 -3.25397808e+01 -2.27834202e+01 -1.62425533e+01\n",
            "  -1.22963501e+01 -1.04420204e+01]\n",
            " [-3.49108603e+01 -4.34421526e+01 -6.80000000e+01 -4.45884177e+01\n",
            "  -3.45733815e+01 -2.58966894e+01 -1.88455156e+01 -1.37508525e+01\n",
            "  -1.05101474e+01 -8.94282371e+00]\n",
            " [-2.97415728e+01 -3.36282672e+01 -3.94738345e+01 -3.25397808e+01\n",
            "  -2.58966894e+01 -1.98832050e+01 -1.48354516e+01 -1.10022895e+01\n",
            "  -8.45254739e+00 -7.18079355e+00]\n",
            " [-2.33181490e+01 -2.45991792e+01 -2.56200158e+01 -2.27834202e+01\n",
            "  -1.88455156e+01 -1.48354516e+01 -1.12533705e+01 -8.37943162e+00\n",
            "  -6.36538818e+00 -5.31290899e+00]\n",
            " [-1.78879909e+01 -1.81265270e+01 -1.79070833e+01 -1.62425533e+01\n",
            "  -1.37508525e+01 -1.10022895e+01 -8.37943162e+00 -6.12757124e+00\n",
            "  -4.41549927e+00 -3.42380608e+00]\n",
            " [-1.41802226e+01 -1.40583625e+01 -1.35326282e+01 -1.22963501e+01\n",
            "  -1.05101474e+01 -8.45254739e+00 -6.36538818e+00 -4.41549927e+00\n",
            "  -2.71709718e+00 -1.45831386e+00]\n",
            " [-1.23315193e+01 -1.21048860e+01 -1.15169307e+01 -1.04420204e+01\n",
            "  -8.94282371e+00 -7.18079355e+00 -5.31290899e+00 -3.42380608e+00\n",
            "  -1.45831386e+00 -6.50364445e-02]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iShTWpQTjTaS"
      },
      "source": [
        "**Policy iteration exercise**: \n",
        "\n",
        "Try the following policy iteration algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKV69N7HjOzw",
        "outputId": "dd41a53f-0287-4568-983d-54e5da024fa9"
      },
      "source": [
        "# Policy iteration\n",
        "if __name__== \"__main__\":\n",
        "  # Create the world\n",
        "  w = World((10, 10), [(9, 9)], [(4, 2), (2, 4)])\n",
        "  # Create the agent\n",
        "  agent = Agent(w, (0, 0))\n",
        "  # Create the policy\n",
        "  actions = [(-1, 0), (1, 0), (0, -1), (0, 1)] # All the possible actions\n",
        "  policy = []\n",
        "  policy.append(np.zeros(w.size)) # Always apply the first action\n",
        "  # Main loop: Repeat until policy convergence\n",
        "  for policyEpoch in range(1, 100):\n",
        "    # Evaluation loop 1: Repeat until the value difference is neglectable\n",
        "    theta = 0.01\n",
        "    # Initialize the value matrix (all to zero)\n",
        "    v = []\n",
        "    v.append(np.zeros(w.size))\n",
        "    for valueEpoch in range(1, 100):\n",
        "      vp = np.zeros(w.size)\n",
        "      # Evaluation loop 2: Sweep the state space to update the values\n",
        "      for i in range(w.size[0]):\n",
        "        for j in range(w.size[1]):\n",
        "          state = (i, j)\n",
        "          action = int(policy[policyEpoch-1][i][j])\n",
        "          # Estimate the transitions and rewards\n",
        "          nextState, reward = agent.checkAction(state, actions[action])\n",
        "          # Update the value\n",
        "          vp[i][j] = reward + v[valueEpoch-1][nextState[0]][nextState[1]]\n",
        "      v.append(vp) #  Save all the values to analyze them, but the algorithm only needs the two last valuesÇ\n",
        "      # Difference between the two last matrices\n",
        "      dif = np.abs(np.subtract(v[valueEpoch-1], v[valueEpoch-2]))\n",
        "      value = np.max(dif) / np.max(vp)\n",
        "      if value < theta: \n",
        "        #print('Época valor: ' + str(valueEpoch))\n",
        "        #print('Matriz de valor: ' + str(vp))  \n",
        "        break\n",
        "    policyp = np.zeros(w.size)\n",
        "    # Improvement loop 1: Sweep the state space to improve the policy\n",
        "    for i in range(w.size[0]):\n",
        "      for j in range(w.size[1]):\n",
        "        state = (i, j) \n",
        "        # Improvement loop 2: Sweep all the possible actions\n",
        "        bestAction = 0\n",
        "        maxValue = -1000\n",
        "        for k in range(len(actions)):\n",
        "          action = actions[k]\n",
        "          nextState, reward = agent.checkAction(state, action)\n",
        "          value = reward + v[len(v)-1][nextState[0]][nextState[1]]\n",
        "          # Select the best action\n",
        "          if value > maxValue:\n",
        "            bestAction = k\n",
        "            maxValue = value\n",
        "        policyp[i][j] = bestAction\n",
        "    policy.append(policyp) # Save all the values to analyze them, but the algorithm only needs the two last values\n",
        "    if np.equal(policy[policyEpoch-2],policy[policyEpoch-1]).all():\n",
        "      #print('Época política: ' + str(policyEpoch))\n",
        "      #print('Matriz de política: ' + str(policy))  \n",
        "      break\n",
        "  print('Valor:\\n' + str(v[len(v)-1]))\n",
        "  print('Política:\\n' + str(policy[len(policy)-1]))\n",
        "  printPolicy(w, policyp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: RuntimeWarning: divide by zero encountered in double_scalars\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valor:\n",
            "[[ 82.  83.  84.  85.  86.  87.  88.  89.  90.  91.]\n",
            " [ 83.  84.  85.  86.  87.  88.  89.  90.  91.  92.]\n",
            " [ 84.  85.  86.  87. -99.  89.  90.  91.  92.  93.]\n",
            " [ 85.  86.  87.  88.  89.  90.  91.  92.  93.  94.]\n",
            " [ 86.  87. -99.  89.  90.  91.  92.  93.  94.  95.]\n",
            " [ 87.  88.  89.  90.  91.  92.  93.  94.  95.  96.]\n",
            " [ 88.  89.  90.  91.  92.  93.  94.  95.  96.  97.]\n",
            " [ 89.  90.  91.  92.  93.  94.  95.  96.  97.  98.]\n",
            " [ 90.  91.  92.  93.  94.  95.  96.  97.  98.  99.]\n",
            " [ 91.  92.  93.  94.  95.  96.  97.  98.  99.  99.]]\n",
            "Política:\n",
            "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 3. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 0. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 3. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [3. 3. 3. 3. 3. 3. 3. 3. 3. 1.]]\n",
            "[ V  V  V  V  V  V  V  V  V  V \n",
            " V  V  V  V  >  V  V  V  V  V \n",
            " V  V  V  V  ^  V  V  V  V  V \n",
            " V  V  >  V  V  V  V  V  V  V \n",
            " V  V  ^  V  V  V  V  V  V  V \n",
            " V  V  V  V  V  V  V  V  V  V \n",
            " V  V  V  V  V  V  V  V  V  V \n",
            " V  V  V  V  V  V  V  V  V  V \n",
            " V  V  V  V  V  V  V  V  V  V \n",
            " >  >  >  >  >  >  >  >  >  V ]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFu4VLF1kXa2"
      },
      "source": [
        "# Value-based method:\n",
        "\n",
        "This is a value-based algorithm that allows the agent to learn how to move through *GridWorld*.\n",
        "\n",
        "The agent must go from (0, 0) to (9, 9) avoiding the obstacles in (4, 2) and (2, 4). The movements of the agent can be left (-1, 0), right (1, 0), up (0, -1) and down (0, 1).\n",
        "\n",
        "**Value iteration exercise**: \n",
        "\n",
        "Try the following value-based algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqs-Yh1ZkTL1",
        "outputId": "20db91ef-2b91-43fa-a2f9-ec96a5bffb2e"
      },
      "source": [
        "# Value iteration\n",
        "if __name__== \"__main__\":\n",
        "  # Create the world\n",
        "  w = World((10, 10), [(9, 9)], [(4, 2), (2, 4)])\n",
        "  printMap(w)\n",
        "  # Create the agent\n",
        "  agent = Agent(w, (0, 0))\n",
        "  # Create the policy\n",
        "  actions = [(-1, 0), (1, 0), (0, -1), (0, 1)] # All the possible actions\n",
        "  policy = np.zeros(w.size)\n",
        "  # Initialize the value matrix (all to zero)\n",
        "  v = []\n",
        "  v.append(np.zeros(w.size))\n",
        "  # Loop 1: Repeat until the value difference is neglectable\n",
        "  theta = 0.01\n",
        "  for valueEpoch in range(1, 100):\n",
        "    vp = np.zeros(w.size)\n",
        "    # Loop 2: Sweep the state space to update the values\n",
        "    for i in range(w.size[0]):\n",
        "      for j in range(w.size[1]):\n",
        "        state = (i, j)\n",
        "        # Loop 3: Sweep the possible actions \n",
        "        bestAction = 0\n",
        "        maxValue = -1000\n",
        "        for k in range(len(actions)):\n",
        "          action = actions[k]\n",
        "          nextState, reward = agent.checkAction(state, action)\n",
        "          value = reward + v[len(v)-1][nextState[0]][nextState[1]]\n",
        "          # Select the best action\n",
        "          if value > maxValue:\n",
        "            bestAction = k\n",
        "            maxValue = value\n",
        "        # Estimate the transitions and rewards\n",
        "        action = actions[bestAction]\n",
        "        nextState, reward = agent.checkAction(state, action)\n",
        "        # Update the value\n",
        "        vp[i][j] = reward + v[valueEpoch-1][nextState[0]][nextState[1]]\n",
        "        # Update the policy\n",
        "        policy[i][j] = bestAction\n",
        "    v.append(vp) # Save all the values to analyze them, but the algorithm only needs the two last values\n",
        "    # Difference between the two last matrices\n",
        "    dif = np.abs(np.subtract(v[valueEpoch-1], v[valueEpoch-2]))\n",
        "    value = np.max(dif) / np.max(vp)\n",
        "    if value < theta: \n",
        "      #print('Época valor: ' + str(valueEpoch))\n",
        "      #print('Matriz de valor: ' + str(vp))  \n",
        "      break\n",
        "  print('Valor:' + str(v[len(v)-1]))\n",
        "  print('Política:' + str(policy))\n",
        "  printPolicy(w, policy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ O  O  O  O  O  O  O  O  O  O \n",
            " O  O  O  O  O  O  O  O  O  O \n",
            " O  O  O  O  X  O  O  O  O  O \n",
            " O  O  O  O  O  O  O  O  O  O \n",
            " O  O  X  O  O  O  O  O  O  O \n",
            " O  O  O  O  O  O  O  O  O  O \n",
            " O  O  O  O  O  O  O  O  O  O \n",
            " O  O  O  O  O  O  O  O  O  O \n",
            " O  O  O  O  O  O  O  O  O  O \n",
            " O  O  O  O  O  O  O  O  O  F ]\n",
            "\n",
            "Valor:[[ 82.  83.  84.  85.  86.  87.  88.  89.  90.  91.]\n",
            " [ 83.  84.  85.  86.  87.  88.  89.  90.  91.  92.]\n",
            " [ 84.  85.  86.  87. -99.  89.  90.  91.  92.  93.]\n",
            " [ 85.  86.  87.  88.  89.  90.  91.  92.  93.  94.]\n",
            " [ 86.  87. -99.  89.  90.  91.  92.  93.  94.  95.]\n",
            " [ 87.  88.  89.  90.  91.  92.  93.  94.  95.  96.]\n",
            " [ 88.  89.  90.  91.  92.  93.  94.  95.  96.  97.]\n",
            " [ 89.  90.  91.  92.  93.  94.  95.  96.  97.  98.]\n",
            " [ 90.  91.  92.  93.  94.  95.  96.  97.  98.  99.]\n",
            " [ 91.  92.  93.  94.  95.  96.  97.  98.  99.  99.]]\n",
            "Política:[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 3. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 0. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 3. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [3. 3. 3. 3. 3. 3. 3. 3. 3. 1.]]\n",
            "[ V  V  V  V  V  V  V  V  V  V \n",
            " V  V  V  V  >  V  V  V  V  V \n",
            " V  V  V  V  ^  V  V  V  V  V \n",
            " V  V  >  V  V  V  V  V  V  V \n",
            " V  V  ^  V  V  V  V  V  V  V \n",
            " V  V  V  V  V  V  V  V  V  V \n",
            " V  V  V  V  V  V  V  V  V  V \n",
            " V  V  V  V  V  V  V  V  V  V \n",
            " V  V  V  V  V  V  V  V  V  V \n",
            " >  >  >  >  >  >  >  >  >  V ]\n",
            "\n"
          ]
        }
      ]
    }
  ]
}